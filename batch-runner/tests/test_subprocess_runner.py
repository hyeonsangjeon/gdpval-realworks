"""Tests for core/subprocess_runner.py"""

import pytest
from unittest.mock import Mock, MagicMock, patch
from pathlib import Path

from core.config import DEFAULT_TOKENS
from core.subprocess_runner import SubprocessRunner


@pytest.fixture
def mock_llm_client():
    """Create mock LLM client"""
    client = Mock()
    return client


@pytest.fixture
def subprocess_runner(mock_llm_client):
    """Create SubprocessRunner with mock client"""
    return SubprocessRunner(mock_llm_client)


def test_subprocess_runner_initialization(subprocess_runner):
    """Test SubprocessRunner initializes with llm_client"""
    assert subprocess_runner.llm_client is not None
    assert subprocess_runner.max_completion_tokens == DEFAULT_TOKENS["code_generation"]


def test_subprocess_runner_token_override(mock_llm_client):
    """Custom max_completion_tokens should override default"""
    runner = SubprocessRunner(mock_llm_client, max_completion_tokens=2222)
    assert runner.max_completion_tokens == 2222


def test_extract_code_python_block(subprocess_runner):
    """Test code extraction from ```python blocks"""
    text = """Here's the code:
```python
print("Hello, World!")
```
"""
    code = subprocess_runner._extract_code(text)
    assert code == 'print("Hello, World!")'


def test_extract_code_multiple_blocks(subprocess_runner):
    """Test code extraction with multiple blocks (returns first)"""
    text = """Code 1:
```python
print("First")
```

Code 2:
```python
print("Second")
```
"""
    code = subprocess_runner._extract_code(text)
    assert "First" in code


def test_extract_code_generic_block(subprocess_runner):
    """Test code extraction from generic ``` blocks"""
    text = """```
import sys
print("Hello")
```"""
    code = subprocess_runner._extract_code(text)
    assert code is not None
    assert "import" in code or "print" in code


def test_extract_code_no_block(subprocess_runner):
    """Test code extraction returns None when no code block found"""
    text = "This is just plain text with no code blocks."
    code = subprocess_runner._extract_code(text)
    assert code is None


def test_execute_safely_simple_script(subprocess_runner):
    """Test safe execution of simple Python script"""
    code = """
print("Hello from subprocess!")
with open("output.txt", "w") as f:
    f.write("Test output")
"""
    result = subprocess_runner._execute_safely(code, reference_files=None)

    assert result["success"] is True
    assert "Hello from subprocess!" in result["text"]
    assert len(result["files"]) == 1
    assert result["files"][0]["filename"] == "output.txt"


def test_execute_safely_file_generation(subprocess_runner):
    """Test execution generates files correctly"""
    code = """
import json

# Create JSON file
data = {"test": "value"}
with open("data.json", "w") as f:
    json.dump(data, f)

# Create text file
with open("output.md", "w") as f:
    f.write("# Test Markdown")

print("Files created")
"""
    result = subprocess_runner._execute_safely(code)

    assert result["success"] is True
    assert len(result["files"]) == 2
    filenames = [f["filename"] for f in result["files"]]
    assert "data.json" in filenames
    assert "output.md" in filenames


def test_execute_safely_timeout(subprocess_runner):
    """Test execution timeout protection"""
    code = """
import time
time.sleep(200)  # Exceeds 120s timeout
"""
    result = subprocess_runner._execute_safely(code)

    assert result["success"] is False
    assert "timeout" in result["error"].lower()


def test_execute_safely_error_handling(subprocess_runner):
    """Test execution handles errors gracefully"""
    code = """
raise ValueError("Test error")
"""
    result = subprocess_runner._execute_safely(code)

    assert result["success"] is False
    assert "ValueError" in result["error"] or "Test error" in result["text"]


def test_execute_safely_no_api_keys_in_env(subprocess_runner):
    """Test subprocess does not inherit API keys"""
    code = """
import os
api_key = os.environ.get("AZURE_OPENAI_API_KEY")
hf_token = os.environ.get("HF_TOKEN")
print(f"API_KEY: {api_key}")
print(f"HF_TOKEN: {hf_token}")
"""
    result = subprocess_runner._execute_safely(code)

    assert result["success"] is True
    assert "None" in result["text"]  # Keys should be None


@patch("core.subprocess_runner.complete")
def test_run_full_pipeline(mock_complete, subprocess_runner):
    """Test full run pipeline with mocked LLM response"""
    # Mock LLM response with code
    mock_response = Mock()
    mock_response.choices = [
        Mock(message=Mock(content="""```python
with open("test.txt", "w") as f:
    f.write("Generated by LLM")
print("Done")
```"""))
    ]
    mock_response.usage = Mock(total_tokens=100)

    mock_complete.return_value = (mock_response, 100)

    result = subprocess_runner.run(
        task_prompt="Create a test file",
        model="gpt-4"
    )

    assert result["success"] is True
    assert len(result["files"]) == 1
    assert result["files"][0]["filename"] == "test.txt"
    assert result["files"][0]["content"] == b"Generated by LLM"


@patch("core.subprocess_runner.complete")
def test_run_no_code_generated(mock_complete, subprocess_runner):
    """Test run handles case when LLM doesn't generate code"""
    mock_response = Mock()
    mock_response.choices = [
        Mock(message=Mock(content="I cannot generate code for this task."))
    ]

    mock_complete.return_value = (mock_response, 100)

    result = subprocess_runner.run(
        task_prompt="Test task",
        model="gpt-4"
    )

    assert result["success"] is False
    assert "No Python code found" in result["error"]


def test_code_gen_prompt_loaded_from_yaml(subprocess_runner):
    """Test prompt is loaded from external YAML file"""
    assert subprocess_runner.prompt_data is not None
    assert "user_prompt" in subprocess_runner.prompt_data
    assert "system_message" in subprocess_runner.prompt_data
    prompt = subprocess_runner.prompt_data["user_prompt"]
    assert "python-docx" in prompt
    assert "reportlab" in prompt
    assert "openpyxl" in prompt
    assert "Pillow" in prompt
    assert "matplotlib" in prompt


def test_run_with_reference_files(subprocess_runner, tmp_path):
    """Test execution with reference files"""
    # Create temporary reference file
    ref_file = tmp_path / "reference.txt"
    ref_file.write_text("Reference content")

    code = """
# Read reference file
with open("reference.txt", "r") as f:
    content = f.read()

# Create output
with open("output.txt", "w") as f:
    f.write(f"Processed: {content}")
"""
    result = subprocess_runner._execute_safely(
        code,
        reference_files=[str(ref_file)]
    )

    assert result["success"] is True
    output_file = next(f for f in result["files"] if f["filename"] == "output.txt")
    assert b"Processed: Reference content" in output_file["content"]
